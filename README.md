# Towards Seamless Egocentric Hand Action Recognition in Mixed Reality
**2023 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)**

Sakib Reza, Yuexi Zhang, Octavia Camps, Mohsen Moghaddam

Northeastern University, Boston, MA, United States  

[[`Paper Link`](https://ieeexplore.ieee.org/abstract/document/10322204/)]   

## Instruction 
### Hand Action Recognition Model
The hand Action Recognition Model's code can be found here - `FR-Head-main`. For training, testing, and other instructions, please follow the reference repository - [`FR-Head`](https://github.com/zhysora/FR-Head)

### Data Collection App
The Unity scene corresponding to the data collection app can be found here - `Assets/Scenes/Multimodal Step Detection.unity`
### Dataset
The hand action recognition dataset (PHI16) can be downloaded from here - [`GDrive Link`](https://drive.google.com/drive/folders/19E60rUmyds0M5JeOGGRGFo7XoN1ZIfVt?usp=sharing)

------
If you find our repo or paper useful, please give us a star and cite
```
@inproceedings{reza2023towards,
  title={Towards Seamless Egocentric Hand Action Recognition in Mixed Reality},
  author={Reza, Sakib and Zhang, Yuexi and Camps, Octavia and Moghaddam, Mohsen},
  booktitle={2023 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)},
  pages={411--416},
  year={2023},
  organization={IEEE}
}
```
